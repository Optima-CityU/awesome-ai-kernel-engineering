# Awesome AI Kernel Engineering

## Methods
|  Title  |   Venue  |   Date   |   Code   |   topic   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [CudaLLM: Training Language Models to Generate High-Performance CUDA Kernels](https://huggingface.co/ByteDance-Seed/cudaLLM-8B) <br> | HugginFace | 2025.08 | [Github](https://github.com/ByteDance-Seed/cudaLLM) | CUDA, Finetuning |
| [OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning](https://arxiv.org/abs/2508.12551) <br> | arXiv | 2025.08 | - | General Kernel, OS Kernel |
| [TimelyHLS: LLM-Based Timing-Aware and Architecture-Specific FPGA HLS Optimization](https://arxiv.org/pdf/2507.17962) <br> | arXiv | 2025.07 | - | Hardware_as_Code, HLS |
| ![Star](https://img.shields.io/github/stars/AMD-AIG-AIMA/GEAK-agent.svg?style=social&label=Star) <br> [**GEAK: Introducing Triton Kernel AI Agent & Evaluation Benchmarks**](https://arxiv.org/abs/2507.23194) <br> | arXiv | 2025.07 | [Github](https://github.com/AMD-AIG-AIMA/GEAK-agent) | Triton (AMD), Iterative Search |
| [**GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning**](https://arxiv.org/abs/2507.19457) <br> | arXiv | 2025.07 | - | AMD NPU + CUDA, Prompt Engineering |
| ![Star](https://img.shields.io/github/stars/deepreinforce-ai/CUDA-L1.svg?style=social&label=Star) <br> [**CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning**](https://arxiv.org/abs/2507.14111) <br> | arXiv | 2025.07 | [Github](https://github.com/deepreinforce-ai/CUDA-L1) | CUDA, Finetuning |
| [**Omniwise: Predicting GPU Kernels Performance with LLMs**](https://arxiv.org/abs/2506.20886) <br> | arXiv | 2025.06 | - | AMD NPU, Surrogate Modeling |
| [**Kevin: Multi-Turn RL for Generating CUDA Kernels**](https://openreview.net/forum?id=HLeyRyV55o) <br> | EXAIT Workshop @ ICML | 2025.06 | - | CUDA, Finetuning |
| [**GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization**](https://openreview.net/forum?id=K4XSvet59a) <br> | ES-FoMo Workshop @ ICML | 2025.06 | - | AMD, Iterative Search |
| [**AlphaEvolve: A coding agent for scientific and algorithmic discovery**](https://arxiv.org/abs/2506.13131) <br> | arXiv | 2025.06 | [Github](https://github.com/codelion/openevolve)[^1] | TPU, Agentic System |
| [**CUDA-LLM: LLMs Can Write Efficient CUDA Kernels**](https://arxiv.org/abs/2506.09092) <br> | arXiv | 2025.06 | - | CUDA, Prompt Engineering (?) |
| [**The AI CUDA Engineer: Agentic CUDA Kernel Discovery, Optimization and Composition**](https://pub.sakana.ai/ai-cuda-engineer) <br> | arXiv | 2025.02 | [HuggingFace](https://huggingface.co/datasets/SakanaAI/AI-CUDA-Engineer-Archive) | CUDA, Agent + Iterative Search + RAG |
| [**ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?**](https://aclanthology.org/2024.emnlp-main.859/) (Waghjale et al., EMNLP 2024) <br> | EMNLP 2024 | 2024.11 | - | LLM4Code |

[^1]: A public implementation of AlphaEvolve.

## Datasets and Benchmarks
|  Title  |   Venue  |   Date   |   Code   |   topic   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/wzzll123/MultiKernelBench.svg?style=social&label=Star) <br> [**MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation**](https://www.arxiv.org/abs/2507.17773) <br> | arXiv | 2025.07 | [Github](https://github.com/wzzll123/MultiKernelBench) | CUDA + CANN + TPU |
| [**NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers**](https://arxiv.org/abs/2507.14403) <br> | arXiv | 2025.07 | - | NPU |
| ![Star](https://img.shields.io/github/stars/thunlp/TritonBench.svg?style=social&label=Star) <br> [**TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators**](https://arxiv.org/abs/2502.14752) <br> | ICML | 2025.02 | [Github](https://github.com/thunlp/TritonBench) | Triton (CUDA) |
| ![Star](https://img.shields.io/github/stars/ScalingIntelligence/KernelBench.svg?style=social&label=Star) <br> [**KernelBench: Can LLMs Write Efficient GPU Kernels?**](https://arxiv.org/abs/2502.10517) <br> | ICML | 2025.02 | [Github](https://github.com/ScalingIntelligence/KernelBench) | CUDA |
| [**Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation**](https://arxiv.org/abs/2309.07103) <br> | [LCPC](http://www.lcpcworkshop.org/LCPC23/) | 2023.09 | - |  |

## Others
|  Title  |   Date   |   topic   |
|:--------|:--------:|:--------:|
|[AMD Developer Challenge 2025](https://www.datamonsters.com/amd-developer-challenge-2025)| 2025.04 | AMD GPU |
|[GPU Mode Learderboard](https://www.gpumode.com/)| - | AMD + CUDA |
